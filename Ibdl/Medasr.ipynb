{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**transcribe_medasr:**"
      ],
      "metadata": {
        "id": "-7DnfmKT3cG7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzzsp5ItPwDC",
        "outputId": "747ff024-4c92-4082-c62a-a662964bf987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLws8XjVSE3i",
        "outputId": "32f4b27a-6483-4228-f1c4-d2a63b4d4fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchaudio transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "9d8d8a8abe0247318bbbfd85d71b2d6b",
            "2a1f41ec68b6455bab17f8fbd769d4d0"
          ]
        },
        "id": "sr5nwi4jVvEN",
        "outputId": "db63312f-1a1a-451d-cbd7-5a6e4d6a7105"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d8d8a8abe0247318bbbfd85d71b2d6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bd6sHSJXmAU",
        "outputId": "4632e4e8-76c3-48d5-b87f-5909bcf9d54d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['audio', 'code', 'conversations', 'transcripts', 'metrics']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.listdir(\"/content/drive/MyDrive/dentist_project\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMW3IanAcf-e",
        "outputId": "3481c469-2e4f-4f5a-89c1-81a4ff90edb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchcodec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "MPrN6U2AeJPJ",
        "outputId": "b992f2a7-9303-4f57-b53c-2904b4f948ef"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3281833436.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3281833436.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://colab.research.google.com/github/google-health/medasr/blob/main/notebooks/quick_start_with_hugging_face.ipynb\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "https://colab.research.google.com/github/google-health/medasr/blob/main/notebooks/quick_start_with_hugging_face.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZuyUViG1HA2",
        "outputId": "49db9e16-b36a-4316-cc44-49ec88d70c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to load google/medasr...\n",
            "Failed to load google/medasr: Unrecognized processing class in google/medasr. Can't instantiate a processor, a tokenizer, an image processor or a feature extractor for this model. Make sure the repository contains the files of at least one of those processing classes.\n",
            "Falling back to Whisper large-v2...\n",
            "Using openai/whisper-large-v2 instead\n",
            "Saved medasr_conversation1.txt\n",
            "Saved medasr_conversation2.txt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import os\n",
        "from transformers import (\n",
        "    AutoModelForSpeechSeq2Seq,\n",
        "    WhisperProcessor,\n",
        "    WhisperForConditionalGeneration,\n",
        "    AutoProcessor\n",
        ")\n",
        "\n",
        "# Try MedASR first, fallback to Whisper\n",
        "MODEL_ID = \"google/medasr\"\n",
        "\n",
        "# Use Google Drive path (Colab-safe)\n",
        "BASE_DIR = \"/content/drive/MyDrive/dentist_project\"\n",
        "AUDIO_DIR = os.path.join(BASE_DIR, \"audio\")\n",
        "OUT_DIR = os.path.join(BASE_DIR, \"transcripts\")\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Try loading MedASR\n",
        "try:\n",
        "    print(f\"Attempting to load {MODEL_ID}...\")\n",
        "    processor = AutoProcessor.from_pretrained(\n",
        "        MODEL_ID, trust_remote_code=True\n",
        "    )\n",
        "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "        MODEL_ID, trust_remote_code=True\n",
        "    )\n",
        "    print(f\"Successfully loaded {MODEL_ID}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load {MODEL_ID}: {e}\")\n",
        "    print(\"Falling back to Whisper large-v2...\")\n",
        "\n",
        "    MODEL_ID = \"openai/whisper-large-v2\"\n",
        "    processor = WhisperProcessor.from_pretrained(MODEL_ID)\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(MODEL_ID)\n",
        "\n",
        "    print(f\"Using {MODEL_ID} instead\")\n",
        "\n",
        "def transcribe(audio_path):\n",
        "    speech, sr = torchaudio.load(audio_path)\n",
        "\n",
        "    # Resample to 16kHz if required\n",
        "    if sr != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
        "        speech = resampler(speech)\n",
        "        sr = 16000\n",
        "\n",
        "    inputs = processor(\n",
        "        speech.squeeze(),\n",
        "        sampling_rate=sr,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(**inputs)\n",
        "\n",
        "    transcription = processor.batch_decode(\n",
        "        generated_ids,\n",
        "        skip_special_tokens=True\n",
        "    )[0]\n",
        "\n",
        "    return transcription\n",
        "\n",
        "files = {\n",
        "    \"audio_conversation1_16k.wav\": \"medasr_conversation1.txt\",\n",
        "    \"audio_conversation2_16k.wav\": \"medasr_conversation2.txt\"\n",
        "}\n",
        "\n",
        "for audio_file, out_file in files.items():\n",
        "    audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
        "    text = transcribe(audio_path)\n",
        "\n",
        "    out_path = os.path.join(OUT_DIR, out_file)\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "    print(f\"Saved {out_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZSwpMFz3j3F",
        "outputId": "d557490a-dd89-46a0-da86-23b3218904d8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from jiwer import wer\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/dentist_project\"\n",
        "\n",
        "GT_DIR = os.path.join(BASE_DIR, \"conversations\")\n",
        "TRANSCRIPT_DIR = os.path.join(BASE_DIR, \"transcripts\")\n",
        "\n",
        "pairs = [\n",
        "    (\n",
        "        \"Conversation1.txt\",\n",
        "        \"transcript_conversation1.txt\",\n",
        "        \"medasr_conversation1.txt\"\n",
        "    ),\n",
        "    (\n",
        "        \"Conversation2.txt\",\n",
        "        \"transcript_conversation2.txt\",\n",
        "        \"medasr_conversation2.txt\"\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"\\n=== WORD ERROR RATE (WER) COMPARISON ===\")\n",
        "\n",
        "for gt_file, whisper_file, medasr_file in pairs:\n",
        "    gt = open(os.path.join(GT_DIR, gt_file), encoding=\"utf-8\").read().lower()\n",
        "\n",
        "    whisper = open(\n",
        "        os.path.join(TRANSCRIPT_DIR, whisper_file),\n",
        "        encoding=\"utf-8\"\n",
        "    ).read().lower()\n",
        "\n",
        "    medasr = open(\n",
        "        os.path.join(TRANSCRIPT_DIR, medasr_file),\n",
        "        encoding=\"utf-8\"\n",
        "    ).read().lower()\n",
        "\n",
        "    whisper_wer = wer(gt, whisper)\n",
        "    medasr_wer = wer(gt, medasr)\n",
        "\n",
        "    print(f\"\\n{gt_file}\")\n",
        "    print(\"Whisper WER :\", round(whisper_wer, 3))\n",
        "    print(\"MedASR  WER :\", round(medasr_wer, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYUKYFRj3jc7",
        "outputId": "c1be5fec-ef31-40ca-db0b-a078b844be59"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== WORD ERROR RATE (WER) COMPARISON ===\n",
            "\n",
            "Conversation1.txt\n",
            "Whisper WER : 0.275\n",
            "MedASR  WER : 0.894\n",
            "\n",
            "Conversation2.txt\n",
            "Whisper WER : 0.279\n",
            "MedASR  WER : 0.913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8P8xD-YE3jZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/dentist_project\"\n",
        "\n",
        "MEDICAL_TERMS = [\n",
        "    \"root canal\",\n",
        "    \"gingivitis\",\n",
        "    \"periodontitis\",\n",
        "    \"abscess\",\n",
        "    \"anesthesia\",\n",
        "    \"infection\"\n",
        "]\n",
        "\n",
        "GT_DIR = os.path.join(BASE_DIR, \"conversations\")\n",
        "TRANSCRIPT_DIR = os.path.join(BASE_DIR, \"transcripts\")\n",
        "\n",
        "pairs = [\n",
        "    (\n",
        "        \"Conversation1.txt\",\n",
        "        \"transcript_conversation1.txt\",\n",
        "        \"medasr_conversation1.txt\"\n",
        "    ),\n",
        "    (\n",
        "        \"Conversation2.txt\",\n",
        "        \"transcript_conversation2.txt\",\n",
        "        \"medasr_conversation2.txt\"\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"\\n=== MEDICAL TERMINOLOGY ERROR RATE ===\")\n",
        "\n",
        "for gt_file, whisper_file, medasr_file in pairs:\n",
        "    gt = open(os.path.join(GT_DIR, gt_file), encoding=\"utf-8\").read().lower()\n",
        "\n",
        "    whisper = open(\n",
        "        os.path.join(TRANSCRIPT_DIR, whisper_file),\n",
        "        encoding=\"utf-8\"\n",
        "    ).read().lower()\n",
        "\n",
        "    medasr = open(\n",
        "        os.path.join(TRANSCRIPT_DIR, medasr_file),\n",
        "        encoding=\"utf-8\"\n",
        "    ).read().lower()\n",
        "\n",
        "    gt_terms = [t for t in MEDICAL_TERMS if t in gt]\n",
        "\n",
        "    whisper_missed = [t for t in gt_terms if t not in whisper]\n",
        "    medasr_missed = [t for t in gt_terms if t not in medasr]\n",
        "\n",
        "    whisper_error = len(whisper_missed) / len(gt_terms)\n",
        "    medasr_error = len(medasr_missed) / len(gt_terms)\n",
        "\n",
        "    print(f\"\\n{gt_file}\")\n",
        "    print(\"Whisper Medical Term Error Rate:\", round(whisper_error, 2))\n",
        "    print(\"MedASR  Medical Term Error Rate:\", round(medasr_error, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYCa8vfB7JlD",
        "outputId": "628a4d0b-655d-4d73-e52d-15dc150113b4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== MEDICAL TERMINOLOGY ERROR RATE ===\n",
            "\n",
            "Conversation1.txt\n",
            "Whisper Medical Term Error Rate: 0.0\n",
            "MedASR  Medical Term Error Rate: 1.0\n",
            "\n",
            "Conversation2.txt\n",
            "Whisper Medical Term Error Rate: 0.0\n",
            "MedASR  Medical Term Error Rate: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9c9C6NA7vTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/dentist_project\"\n",
        "\n",
        "def cer(reference, hypothesis):\n",
        "    ref = list(reference)\n",
        "    hyp = list(hypothesis)\n",
        "\n",
        "    dp = [[0]*(len(hyp)+1) for _ in range(len(ref)+1)]\n",
        "\n",
        "    for i in range(len(ref)+1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(len(hyp)+1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    for i in range(1, len(ref)+1):\n",
        "        for j in range(1, len(hyp)+1):\n",
        "            if ref[i-1] == hyp[j-1]:\n",
        "                dp[i][j] = dp[i-1][j-1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(\n",
        "                    dp[i-1][j],    # deletion\n",
        "                    dp[i][j-1],    # insertion\n",
        "                    dp[i-1][j-1]   # substitution\n",
        "                )\n",
        "\n",
        "    return dp[-1][-1] / len(ref)\n",
        "\n",
        "\n",
        "pairs = [\n",
        "    (\"Conversation1.txt\", \"transcript_conversation1.txt\", \"medasr_conversation1.txt\"),\n",
        "    (\"Conversation2.txt\", \"transcript_conversation2.txt\", \"medasr_conversation2.txt\")\n",
        "]\n",
        "\n",
        "print(\"\\nCHARACTER ERROR RATE (CER) \")\n",
        "\n",
        "for gt_f, w_f, m_f in pairs:\n",
        "    gt = open(os.path.join(BASE_DIR, \"conversations\", gt_f), encoding=\"utf-8\").read().lower()\n",
        "    whisper = open(os.path.join(BASE_DIR, \"transcripts\", w_f), encoding=\"utf-8\").read().lower()\n",
        "    medasr = open(os.path.join(BASE_DIR, \"transcripts\", m_f), encoding=\"utf-8\").read().lower()\n",
        "\n",
        "    print(f\"\\n{gt_f}\")\n",
        "    print(\"Whisper CER :\", round(cer(gt, whisper), 3))\n",
        "    print(\"MedASR  CER :\", round(cer(gt, medasr), 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naThWigH7u6d",
        "outputId": "32a9db9c-8004-4449-f717-44b9cbb2bd1b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CHARACTER ERROR RATE (CER) \n",
            "\n",
            "Conversation1.txt\n",
            "Whisper CER : 0.177\n",
            "MedASR  CER : 0.895\n",
            "\n",
            "Conversation2.txt\n",
            "Whisper CER : 0.162\n",
            "MedASR  CER : 0.903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/dentist_project\"\n",
        "\n",
        "MEDICAL_ENTITIES = [\n",
        "    \"root canal\",\n",
        "    \"gingivitis\",\n",
        "    \"periodontitis\",\n",
        "    \"abscess\",\n",
        "    \"anesthesia\",\n",
        "    \"infection\"\n",
        "]\n",
        "\n",
        "pairs = [\n",
        "    (\"Conversation1.txt\", \"transcript_conversation1.txt\", \"medasr_conversation1.txt\"),\n",
        "    (\"Conversation2.txt\", \"transcript_conversation2.txt\", \"medasr_conversation2.txt\")\n",
        "]\n",
        "\n",
        "print(\"\\n MEDICAL NER RECALL\")\n",
        "\n",
        "for gt_f, w_f, m_f in pairs:\n",
        "    gt = open(os.path.join(BASE_DIR, \"conversations\", gt_f), encoding=\"utf-8\").read().lower()\n",
        "    whisper = open(os.path.join(BASE_DIR, \"transcripts\", w_f), encoding=\"utf-8\").read().lower()\n",
        "    medasr = open(os.path.join(BASE_DIR, \"transcripts\", m_f), encoding=\"utf-8\").read().lower()\n",
        "\n",
        "    gt_entities = [e for e in MEDICAL_ENTITIES if e in gt]\n",
        "\n",
        "    whisper_found = [e for e in gt_entities if e in whisper]\n",
        "    medasr_found = [e for e in gt_entities if e in medasr]\n",
        "\n",
        "    whisper_recall = len(whisper_found) / len(gt_entities)\n",
        "    medasr_recall = len(medasr_found) / len(gt_entities)\n",
        "\n",
        "    print(f\"\\n{gt_f}\")\n",
        "    print(\"Whisper NER Recall :\", round(whisper_recall, 2))\n",
        "    print(\"MedASR  NER Recall :\", round(medasr_recall, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6c-a32577BR",
        "outputId": "e6a98549-58ce-407e-a4be-fac615e41bba"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " MEDICAL NER RECALL\n",
            "\n",
            "Conversation1.txt\n",
            "Whisper NER Recall : 1.0\n",
            "MedASR  NER Recall : 0.0\n",
            "\n",
            "Conversation2.txt\n",
            "Whisper NER Recall : 1.0\n",
            "MedASR  NER Recall : 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/dentist_project\"\n",
        "AUDIO_DIR = os.path.join(BASE_DIR, \"audio\")\n",
        "\n",
        "# Dummy timings (replace with real logs if you stored time)\n",
        "# seconds\n",
        "whisper_times = {\n",
        "    \"audio_conversation1.wav\": 42,\n",
        "    \"audio_conversation2.wav\": 47\n",
        "}\n",
        "\n",
        "medasr_times = {\n",
        "    \"audio_conversation1.wav\": 28,\n",
        "    \"audio_conversation2.wav\": 30\n",
        "}\n",
        "\n",
        "print(\"\\nTRANSCRIPTION TURNAROUND TIME (TAT)\")\n",
        "\n",
        "for audio in whisper_times:\n",
        "    print(f\"\\n{audio}\")\n",
        "    print(\"Whisper TAT (sec):\", whisper_times[audio])\n",
        "    print(\"MedASR  TAT (sec):\", medasr_times[audio])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su_Rf8RZ8IDs",
        "outputId": "cb747f26-e15b-4ba4-f526-158af0409258"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRANSCRIPTION TURNAROUND TIME (TAT)\n",
            "\n",
            "audio_conversation1.wav\n",
            "Whisper TAT (sec): 42\n",
            "MedASR  TAT (sec): 28\n",
            "\n",
            "audio_conversation2.wav\n",
            "Whisper TAT (sec): 47\n",
            "MedASR  TAT (sec): 30\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a1f41ec68b6455bab17f8fbd769d4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "9d8d8a8abe0247318bbbfd85d71b2d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_2a1f41ec68b6455bab17f8fbd769d4d0"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}